{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c83c8fd1",
   "metadata": {},
   "source": [
    "# SPEECH2TEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac92b4",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e91ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U openai-whisper\n",
    "#!pip install transformers\n",
    "#!pip install torchaudio\n",
    "#!pip install pytube\n",
    "#!pip uninstall moviepy\n",
    "#!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "701cb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import whisper\n",
    "import librosa\n",
    "import pytube\n",
    "import moviepy.editor as mp\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6699fb4",
   "metadata": {},
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1674ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(youtube_link, filename='video.mp4'):\n",
    "    yt = pytube.YouTube(youtube_link);\n",
    "    duration = yt.length;\n",
    "    yt = yt.streams.get_highest_resolution();\n",
    "    yt.download(filename = filename);\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d0ce6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audio_clip(video_file_name_path, clip_start, clip_end, file_name = 'audio.mp3'):\n",
    "    clip = mp.VideoFileClip(video_file_name_path).subclip(clip_start,clip_end);\n",
    "    clip.audio.write_audiofile(file_name, logger = None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aaa766f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio_clip(audio_path, model, processor, skip_special_tokens, device, samplerate):\n",
    "    # load audio files\n",
    "    speech, _ = librosa.load(audio_path);\n",
    "    # get the input features\n",
    "    input_features = processor(speech, return_tensors=\"pt\", sampling_rate = samplerate).input_features.to(device);\n",
    "    # generate token ids\n",
    "    predicted_ids = model.generate(input_features);\n",
    "    # decode token ids to text\n",
    "    transcription = processor.batch_decode(predicted_ids, skip_special_tokens=skip_special_tokens);\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f1c99",
   "metadata": {},
   "source": [
    "## TRANSCRIPTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3294fc80",
   "metadata": {},
   "source": [
    "- load model - whisper pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d096b0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "pretained_model = \"openai/whisper-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4600eb24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load model and processor\n",
    "processor = WhisperProcessor.from_pretrained(pretained_model);\n",
    "model = WhisperForConditionalGeneration.from_pretrained(pretained_model).to(device);\n",
    "model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language = \"spanish\", task = \"transcribe\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3325e",
   "metadata": {},
   "source": [
    "- load input - download video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f545a767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/rAAgMDU7ftY?\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youtube_video_id = \"rAAgMDU7ftY\"\n",
    "youtube_link = \"https://www.youtube.com/watch?v=\"+youtube_video_id\n",
    "maxima = download_video(youtube_link);\n",
    "\n",
    "# Youtube\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/'+youtube_video_id+'?\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e971ad",
   "metadata": {},
   "source": [
    "- get output - extract audio clip and transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b885ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_length = 30\n",
    "clips = [(n, min(n+clip_length, maxima)) for n in range(0, maxima, clip_length)]\n",
    "skip_special_tokens = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a2bbdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Los cojones me los está calentando tú. Yo a ti no te disona, ni te estoy hablando de mala manera, ni te estoy vacilando, simplemente que vas a exponer tú más que yo. Y eso no lo veo justo, porque el trabajo gran parte también lo he hecho yo. La intervención la he hecho yo, la tabla la he hecho yo, todo ha interpretado yo. Y le he mandado el correo al profesor porque no lo todos querían y manda vosotros. Todo he hecho yo. Todo que he hecho es la diapositiva.']\n"
     ]
    }
   ],
   "source": [
    "for clip in clips:\n",
    "    #extract audio clip\n",
    "    create_audio_clip('video.mp4', clip[0], clip[1]);\n",
    "    #transcribe audio clip\n",
    "    transcription = transcribe_audio_clip('audio.mp3', model, processor, skip_special_tokens, device, 16000);\n",
    "    print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
